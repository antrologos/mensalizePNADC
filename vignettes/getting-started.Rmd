---
title: "Get Started with PNADCperiods"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Get Started with PNADCperiods}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  eval = FALSE
)
```

## Overview

The `PNADCperiods` package converts Brazil's quarterly PNADC (Pesquisa Nacional por Amostra de Domicilios Continua) survey data into sub-quarterly time series. It identifies which specific **month**, **fortnight** (quinzena), or **week** each survey observation refers to, achieving a **97% determination rate** for months on stacked multi-quarter data.

**Why does this matter?** PNADC quarterly statistics are actually moving averages of three months, which obscures:

- The true timing of economic shocks (when did unemployment peak?)
- The actual magnitude of changes (how high was the peak?)
- Turning points in trends (when did recovery begin?)

PNADCperiods recovers the specific reference period, enabling true monthly (or finer) labor market analysis.

For a detailed explanation of the algorithm, see the [How PNADCperiods Works](how-it-works.html) vignette.

---

## Installation

```{r install}
# Install from GitHub
devtools::install_github("antrologos/mensalizePNADC")
```
```{r}
# Load the package
library(PNADCperiods)
library(data.table)
```

**Dependencies:**

- **Required**: `data.table`, `checkmate`
- **For weight calibration**: `sidrar` (fetches population data from IBGE's SIDRA API)

---

## Two-Step Workflow

The package uses a **two-function workflow**:

1. **`pnadc_identify_periods()`** - Builds a universal crosswalk with reference periods
2. **`pnadc_apply_periods()`** - Applies crosswalk to data and optionally calibrates weights

This separation allows you to:
- Build the crosswalk once from stacked data
- Apply it to any quarterly or annual dataset
- Choose your calibration approach flexibly

---

## Your First Analysis

### Required Input Columns

The algorithm needs these columns from your PNADC data:

| Column | Description |
|--------|-------------|
| `Ano` | Survey year |
| `Trimestre` | Quarter (1-4) |
| `UPA` | Primary Sampling Unit |
| `V1008` | Household identifier |
| `V1014` | Panel identifier (rotation group 1-8) |
| `V2003` | Person identifier |
| `V2008` | Birth day (1-31, or 99 for unknown) |
| `V20081` | Birth month (1-12, or 99 for unknown) |
| `V20082` | Birth year (or 9999 for unknown) |
| `V2009` | Age |

### Step 1: Load Your Data

If you don't have stacked PNADC data yet, see [Download and Prepare Data](download-and-prepare.html) for a complete workflow.

```{r load-data}
# Load your stacked quarterly PNADC data
pnadc <- fread("pnadc_stacked.csv")

# Check data dimensions
cat("Rows:", nrow(pnadc), "\n")
cat("Quarters:", uniqueN(pnadc[, .(Ano, Trimestre)]), "\n")
```

**Important:** The algorithm works best with **stacked multi-quarter data**. Processing a single quarter yields only ~65-75% determination rate, while stacking 2+ years achieves ~97%.

### Step 2: Build the Crosswalk

```{r build-crosswalk}
# Identify reference periods (month, fortnight, week)
crosswalk <- pnadc_identify_periods(pnadc, verbose = TRUE)
```

Output (from real PNADC 2020-2024 data):
```
Building reference period crosswalk...
  Preprocessing data (shared computation)...
  Converting date bounds to period positions...
  Aggregating constraints and determining periods...
  Applying exception rules...
  Assigning reference periods...
  Building crosswalk...

Crosswalk complete:
  - 3,159,265 unique household-quarter observations
  - Month determination: 94.2%
  - Fortnight determination: 2.8%
  - Week determination: 0.9%
```

### Step 3: Understand the Crosswalk

The crosswalk contains one row per **household-quarter** combination (keyed by `Ano`, `Trimestre`, `UPA`, `V1008`, `V1014`) with three granularity levels:

| Output Column | Type | Description |
|---------------|------|-------------|
| **Keys** | | |
| `Ano` | Integer | Survey year |
| `Trimestre` | Integer | Quarter (1-4) |
| `UPA` | Integer | Primary sampling unit |
| `V1008` | Integer | Household identifier |
| `V1014` | Integer | Panel group (1-8) |
| **Month** | | |
| `ref_month` | Date | Reference month as Date (e.g., "2023-01-01") |
| `ref_month_in_quarter` | Integer | Position in quarter: 1, 2, 3, or NA |
| `ref_month_yyyymm` | Integer | YYYYMM format (e.g., 202301) |
| `determined_month` | Logical | TRUE if month was determined |
| **Fortnight** | | |
| `ref_fortnight` | Date | Reference fortnight (1st or 16th of month) |
| `ref_fortnight_in_quarter` | Integer | Position 1-6, or NA |
| `ref_fortnight_yyyyff` | Integer | YYYYFF format (1-24 per year) |
| `determined_fortnight` | Logical | TRUE if fortnight was determined |
| **Week** | | |
| `ref_week` | Date | Reference week (Monday of week) |
| `ref_week_in_quarter` | Integer | Position 1-14, or NA |
| `ref_week_yyyyww` | Integer | ISO YYYYWW format |
| `determined_week` | Logical | TRUE if week was determined |

```{r view-crosswalk}
# View the crosswalk
head(crosswalk)

# Check determination rates (stored as attribute)
attr(crosswalk, "determination_rates")
```

The determination rates attribute returns a list with rates for each period type. See the "Understanding Determination Rates" section below for expected values.

### Step 4: Apply to Your Data

```{r apply-crosswalk}
# Apply crosswalk to a specific quarterly dataset
# For quarterly data, use anchor = "quarter" and weight_var = "V1028"
result <- pnadc_apply_periods(
  pnadc_2023q1,
  crosswalk,
  weight_var = "V1028",
  anchor = "quarter",
  calibrate = TRUE,
  calibration_unit = "month"
)
```

The result includes all original columns plus reference periods and calibrated weights.

#### Understanding the Key Arguments

**`weight_var`** (required): The name of the original PNADC weight variable to use as the starting point for calibration.

| Value | Use When |
|-------|----------|
| `"V1028"` | Quarterly PNADC data (trimestral) |
| `"V1032"` | Annual PNADC data (anual) |

These weights come from IBGE's original calibration and reflect the survey design. The package uses them as input for the sub-quarterly calibration process.

**`anchor`** (required): Specifies whether the data contains all rotation groups for a quarter or a year.

| Value | Use When | Meaning |
|-------|----------|---------|
| `"quarter"` | Quarterly PNADC releases | Each quarter contains all 8 rotation groups interviewed during that quarter |
| `"year"` | Annual PNADC releases | Each year contains specific visits (e.g., visit 1 or visit 5) from households across rotation groups |

This affects how the calibration targets are computed: quarterly data calibrates within each quarter, while annual data calibrates within each year.

**`calibration_unit`**: The time period granularity for weight calibration.

| Value | Calibrates to | Best for |
|-------|---------------|----------|
| `"month"` (default) | Monthly population totals | Most analyses; highest determination rate (~97%) |
| `"fortnight"` | Fortnightly totals | When you need bi-weekly precision (low determination ~2-5%) |
| `"week"` | Weekly totals | Fine-grained analysis (very low determination ~1-2%) |

**What is calibration?** Weight calibration adjusts the survey weights so that weighted totals match known population benchmarks (from IBGE's SIDRA API). This ensures your monthly estimates sum to the correct population totals. Without calibration, sub-quarterly estimates may not properly aggregate to known quarterly totals.

---

## Understanding the Workflow

### Building vs. Applying

**Build the crosswalk once** from stacked data (2+ years recommended):

```{r build-once}
# Stack multiple years of quarterly data
pnadc_stacked <- rbindlist(list(pnadc_2020, pnadc_2021, pnadc_2022, pnadc_2023))

# Build crosswalk (only needs the identification columns)
crosswalk <- pnadc_identify_periods(pnadc_stacked)

# Save for reuse
saveRDS(crosswalk, "crosswalk_2020_2023.rds")
```

**Apply to any dataset** as needed:

```{r apply-many}
# Load saved crosswalk
crosswalk <- readRDS("crosswalk_2020_2023.rds")

# Apply to quarterly data
monthly_q1 <- pnadc_apply_periods(pnadc_2023q1, crosswalk,
                                   weight_var = "V1028",
                                   anchor = "quarter")

# Apply to annual data (with V1032 weights)
monthly_annual <- pnadc_apply_periods(pnadc_annual_2023, crosswalk,
                                       weight_var = "V1032",
                                       anchor = "year")
```

### Calibration Options

The `calibration_unit` parameter controls the granularity of weight calibration:

```{r calibration-units}
# Monthly calibration (default)
result_month <- pnadc_apply_periods(pnadc, crosswalk,
                                     weight_var = "V1028",
                                     anchor = "quarter",
                                     calibration_unit = "month")
# -> Adds weight_monthly column

# Fortnight calibration
result_fortnight <- pnadc_apply_periods(pnadc, crosswalk,
                                         weight_var = "V1028",
                                         anchor = "quarter",
                                         calibration_unit = "fortnight")
# -> Adds weight_fortnight column

# Weekly calibration
result_week <- pnadc_apply_periods(pnadc, crosswalk,
                                    weight_var = "V1028",
                                    anchor = "quarter",
                                    calibration_unit = "week")
# -> Adds weight_weekly column
```

### No Calibration Option

If you only need reference periods without calibrated weights:

```{r no-calibrate}
result <- pnadc_apply_periods(pnadc, crosswalk,
                               weight_var = "V1028",
                               anchor = "quarter",
                               calibrate = FALSE)
# Result has ref_month, ref_fortnight, ref_week but no weight_monthly
```

---

## Using for Monthly Analysis

```{r monthly-analysis}
# Compute monthly unemployment rate
monthly_unemployment <- result[determined_month == TRUE, .(
  unemployment_rate = sum((VD4002 == 2) * weight_monthly, na.rm = TRUE) /
                      sum((VD4001 == 1) * weight_monthly, na.rm = TRUE)
), by = ref_month_yyyymm]

# Compute monthly population
monthly_pop <- result[, .(
  population = sum(weight_monthly, na.rm = TRUE)
), by = ref_month_yyyymm]
```

**Note:** Use `determined_month == TRUE` to filter to observations with determined months.

---

## Understanding Determination Rates

### Why Stack Multiple Quarters?

PNADC uses a **rotating panel** where each household (identified by UPA + V1014) is interviewed in 5 consecutive quarters. The same household is always interviewed in the **same relative month position** within each quarter.

This means birthday constraints from **any** quarter can determine the month for **all** quarters:

```
UPA=123456, V1014=1 appears in 5 quarters:

  2023-Q1: could be Jan or Feb (ambiguous)
  2023-Q2: could be Apr, May, or Jun (ambiguous)
  2023-Q3: must be August (birthday constraint pins it down!)
  2023-Q4: could be Oct or Nov (ambiguous)
  2024-Q1: could be Feb or Mar (ambiguous)

Cross-quarter aggregation:
  Since 2023-Q3 must be month 2, ALL quarters must be month 2.
  Result: ALL 5 quarters are determined!
```

| Processing Mode | Month Rate | Fortnight Rate | Week Rate |
|-----------------|------------|----------------|-----------|
| Single quarter | 65-75% | ~2-5% | ~1-2% |
| Stacked (2+ years) | **~97%** | ~2-5% | ~1-2% |

**Important:** Fortnight and week determination rates remain low (~2-5% and ~1-2%) regardless of stacking because their constraints cannot aggregate across quartersâ€”each quarter's interview timing is independent at the sub-monthly level. Only month determination benefits from cross-quarter aggregation through the rotating panel design.

### What Makes Observations Indeterminate?

About 3% of observations remain indeterminate for months because:

- **Incomplete panel coverage**: First/last quarters in your data have fewer panel visits
- **Missing birth dates**: Some respondents don't report birth date (V2008=99, etc.)
- **Small households**: Fewer people means fewer birthday constraints
- **Unit non-response**: Some households don't respond in all quarters

For the full algorithm explanation, see [How PNADCperiods Works](how-it-works.html).

---

## Next Steps

- **Download PNADC data**: See [Download and Prepare Data](download-and-prepare.html) for a complete workflow to download and stack quarterly microdata from IBGE.

- **Analysis examples**: See [Applied Examples](applied-examples.html) for real-world labor market analysis comparing monthly vs quarterly data, including COVID unemployment and minimum wage validation.

- **Annual PNADC data**: Working with annual income data? See [Monthly Poverty Analysis with Annual PNADC Data](annual-poverty-analysis.html) for the workflow using annual data.

- **Function reference**: Browse the [Reference](../reference/index.html) for documentation of all exported functions.

---

## Quick Reference

### Main Functions

```r
# Step 1: Build crosswalk from stacked data
pnadc_identify_periods(
  data,              # Stacked PNADC data
  verbose = TRUE     # Show progress?
)

# Step 2: Apply crosswalk and optionally calibrate weights
pnadc_apply_periods(
  data,              # PNADC data to augment
  crosswalk,         # Crosswalk from pnadc_identify_periods()
  weight_var,        # REQUIRED: "V1028" (quarterly) or "V1032" (annual)
  anchor,            # REQUIRED: "quarter" or "year"
  calibrate = TRUE,  # Calibrate weights to SIDRA population?
  calibration_unit = "month",  # "month", "fortnight", or "week"
  target_totals = NULL,        # Custom targets (NULL = auto-fetch)
  smooth = TRUE,     # Apply smoothing to weights?
  keep_all = TRUE,   # Return all rows (including undetermined)?
  verbose = TRUE     # Show progress?
)
```

### Performance

| Metric | Value |
|--------|-------|
| Month determination rate | **~97%** (on stacked data) |
| Fortnight determination rate | ~2-5% |
| Week determination rate | ~1-2% |
| Processing time (identification) | ~1 minute for 28M rows |
| Processing time (with calibration) | ~5 minutes for 28M rows |
