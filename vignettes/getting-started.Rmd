---
title: "Get Started with PNADCperiods"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Get Started with PNADCperiods}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  eval = FALSE,
  purl = FALSE
)
```

## Overview

The `PNADCperiods` package converts Brazil's quarterly PNADC (Pesquisa Nacional por Amostra de Domicilios Continua) survey data into sub-quarterly time series. It identifies which specific **month**, **fortnight** (quinzena), or **week** each survey observation refers to.

**Why does this matter?** PNADC quarterly statistics are actually moving averages of three months, which obscures:

- The true timing of economic shocks (when did unemployment peak?)
- The actual magnitude of changes (how high was the peak?)
- Turning points in trends (when did recovery begin?)

PNADCperiods recovers the specific reference period, enabling true monthly (or finer) labor market analysis.

**Key feature:** The identification follows a **nested hierarchy enforced by construction**: fortnights can only be determined if months are determined, and weeks can only be determined if fortnights are determined.

For a detailed explanation of the algorithm, see the [How PNADCperiods Works](how-it-works.html) vignette.

---

## Installation

```{r install}
# Install from GitHub
devtools::install_github("antrologos/PNADCperiods")
```
```{r}
# Load the package
library(PNADCperiods)
library(data.table)
```

**Dependencies:**

- **Required**: `data.table`, `checkmate`
- **For weight calibration**: `sidrar` (fetches population data from IBGE's SIDRA API)

---

## Two-Step Workflow

The package uses a **two-function workflow**:

1. **`pnadc_identify_periods()`** - Builds a crosswalk with reference periods (months, fortnights, weeks)
2. **`pnadc_apply_periods()`** - Applies crosswalk to data and optionally calibrates weights

This separation allows you to:
- Build the crosswalk once from stacked data (which contains birthday variables)
- Apply it to any quarterly or annual dataset
- Choose your calibration approach flexibly

---

## Your First Analysis

### Required Input Columns

The algorithm needs these columns from your PNADC data:

| Column | Description |
|--------|-------------|
| `Ano` | Survey year |
| `Trimestre` | Quarter (1-4) |
| `UPA` | Primary Sampling Unit |
| `V1008` | Household identifier |
| `V1014` | Panel identifier (rotation group 1-8) |
| `V2008` | Birth day (1-31, or 99 for unknown) |
| `V20081` | Birth month (1-12, or 99 for unknown) |
| `V20082` | Birth year (or 9999 for unknown) |
| `V2009` | Age |

### Step 1: Load Your Data

```{r load-data}
# Load your stacked quarterly PNADC data
pnadc <- fread("pnadc_stacked.csv")

# Check data dimensions
cat("Rows:", nrow(pnadc), "\n")
cat("Quarters:", uniqueN(pnadc[, .(Ano, Trimestre)]), "\n")
```

**Important:** The algorithm works best with **stacked multi-quarter data**. Processing a single quarter yields only ~70% month determination rate, while stacking all available years achieves ~97%.

### Step 2: Build the Crosswalk

```{r build-crosswalk}
# Identify reference periods (month, fortnight, week)
crosswalk <- pnadc_identify_periods(pnadc, verbose = TRUE)
```

Output (from real PNADC 2012-2025 data, 55 quarters):
```
Building reference period crosswalk (nested identification)...

Phase 1: Identifying MONTHS (all observations)...
  Step 1.1: Preprocessing data...
  Step 1.2: Computing valid interview Saturdays...
  Step 1.3: Calculating birthdays and adjusting for leap years...
  Step 1.4: Applying birthday constraints...
  Step 1.5: Converting to month positions...
  Step 1.6: Aggregating at UPA-panel level (cross-quarter)...
  Step 1.7: Detecting exception cases...
  Step 1.7b: Applying exception rules...
  Step 1.8: Determining reference months...
  -> Month determination: 97.0% (27,536,744 of 28,395,273 observations)

Phase 2: Identifying FORTNIGHTS (within determined months)...
  Processing 27,536,744 observations with determined months...
  Step 2.1: Calculate fortnight bounds WITHIN the determined month...
  Step 2.2: Aggregating at household level (within quarter)...
  Step 2.3: Determining reference fortnights...
  -> Fortnight determination: 9.2% (2,601,164 of 28,395,273 observations)

Phase 3: Identifying WEEKS (within determined fortnights)...
  Processing 2,601,164 observations with determined fortnights...
  Step 3.2: Aggregating at household level (within quarter)...
  Step 3.4: Determining reference weeks...
  -> Week determination: 3.3% (946,070 of 28,395,273 observations)

Phase 4: Building crosswalk...

========================================
Crosswalk complete (nested identification):
========================================
```

### Step 3: Understand the Crosswalk

The crosswalk contains one row per **observation** (keyed by `UPA`, `V1014`) with IBGE calendar-based output columns:

| Output Column | Type | Description |
|---------------|------|-------------|
| **Keys** | | |
| `Ano` | Integer | Survey year |
| `Trimestre` | Integer | Quarter (1-4) |
| `UPA` | Integer | Primary sampling unit |
| `V1008` | Integer | Household identifier |
| `V1014` | Integer | Panel group (1-8) |
| **Month** | | |
| `ref_month_in_quarter` | Integer | Position in quarter: 1, 2, 3, or NA |
| `ref_month_in_year` | Integer | Position in year: 1-12, or NA |
| `ref_month_yyyymm` | Integer | YYYYMM format (e.g., 202301) |
| `determined_month` | Logical | TRUE if month was determined |
| **Fortnight** | | |
| `ref_fortnight_in_month` | Integer | Position in month: 1 or 2, or NA |
| `ref_fortnight_in_quarter` | Integer | Position 1-6, or NA |
| `ref_fortnight_yyyyff` | Integer | YYYYFF format (e.g., 202303 = 3rd fortnight of 2023) |
| `determined_fortnight` | Logical | TRUE if fortnight was determined |
| **Week** | | |
| `ref_week_in_month` | Integer | Position in month: 1-4, or NA |
| `ref_week_in_quarter` | Integer | Position 1-12, or NA |
| `ref_week_yyyyww` | Integer | YYYYWW format (e.g., 202315) |
| `determined_week` | Logical | TRUE if week was determined |

```{r view-crosswalk}
# View the crosswalk
head(crosswalk)

# Check determination rates
crosswalk[, .(
  month_rate = mean(determined_month),
  fortnight_rate = mean(determined_fortnight),
  week_rate = mean(determined_week)
)]
```

### Step 4: Apply to Your Data

```{r apply-crosswalk}
# Apply crosswalk to a specific quarterly dataset
# For quarterly data, use anchor = "quarter" and weight_var = "V1028"
result <- pnadc_apply_periods(
  pnadc_2023q1,
  crosswalk,
  weight_var = "V1028",
  anchor = "quarter",
  calibrate = TRUE,
  calibration_unit = "month"
)
```

The result includes all original columns plus reference periods and calibrated weights.

#### Understanding the Key Arguments

**`weight_var`** (required): The name of the original PNADC weight variable to use as the starting point for calibration.

| Value | Use When |
|-------|----------|
| `"V1028"` | Quarterly PNADC data (trimestral) |
| `"V1032"` | Annual PNADC data (anual) |

These weights come from IBGE's original calibration and reflect the survey design. The package uses them as input for the sub-quarterly calibration process.

**`anchor`** (required): Specifies whether the data contains all rotation groups for a quarter or a year.

| Value | Use When | Meaning |
|-------|----------|---------|
| `"quarter"` | Quarterly PNADC releases | Each quarter contains all 8 rotation groups interviewed during that quarter |
| `"year"` | Annual PNADC releases | Each year contains specific visits (e.g., visit 1 or visit 5) from households across rotation groups |

This affects how the calibration targets are computed: quarterly data calibrates within each quarter, while annual data calibrates within each year.

**`calibration_unit`**: The time period granularity for weight calibration.

| Value | Calibrates to | Best for |
|-------|---------------|----------|
| `"month"` (default) | Monthly population totals | Most analyses; highest determination rate (~97%) |
| `"fortnight"` | Fortnightly totals | Short-term analysis (strict rate ~9%) |
| `"week"` | Weekly totals | High-frequency monitoring (strict rate ~3%) |

**What is calibration?** Weight calibration adjusts the survey weights so that weighted totals match known population benchmarks (from IBGE's SIDRA API). This ensures your monthly estimates sum to the correct population totals. The package uses adaptive hierarchical raking with 4/2/1 cell levels for month/fortnight/week respectively.

---

## Understanding the Workflow

### Building vs. Applying

**Build the crosswalk once** from stacked data (all available years recommended):

```{r build-once}
# Stack multiple years of quarterly data
pnadc_stacked <- rbindlist(list(pnadc_2020, pnadc_2021, pnadc_2022, pnadc_2023))

# Build crosswalk (only needs the identification columns)
crosswalk <- pnadc_identify_periods(pnadc_stacked)

# Save for reuse
saveRDS(crosswalk, "crosswalk_2020_2023.rds")
```

**Apply to any dataset** as needed:

```{r apply-many}
# Load saved crosswalk
crosswalk <- readRDS("crosswalk_2020_2023.rds")

# Apply to quarterly data
monthly_q1 <- pnadc_apply_periods(pnadc_2023q1, crosswalk,
                                   weight_var = "V1028",
                                   anchor = "quarter")

# Apply to annual data (with V1032 weights)
monthly_annual <- pnadc_apply_periods(pnadc_annual_2023, crosswalk,
                                       weight_var = "V1032",
                                       anchor = "year")
```

### Calibration Options

The `calibration_unit` parameter controls the granularity of weight calibration:

```{r calibration-units}
# Monthly calibration (default)
result_month <- pnadc_apply_periods(pnadc, crosswalk,
                                     weight_var = "V1028",
                                     anchor = "quarter",
                                     calibration_unit = "month")
# -> Adds weight_monthly column

# Fortnight calibration
result_fortnight <- pnadc_apply_periods(pnadc, crosswalk,
                                         weight_var = "V1028",
                                         anchor = "quarter",
                                         calibration_unit = "fortnight")
# -> Adds weight_fortnight column

# Weekly calibration
result_week <- pnadc_apply_periods(pnadc, crosswalk,
                                    weight_var = "V1028",
                                    anchor = "quarter",
                                    calibration_unit = "week")
# -> Adds weight_weekly column
```

### No Calibration Option

If you only need reference periods without calibrated weights:

```{r no-calibrate}
result <- pnadc_apply_periods(pnadc, crosswalk,
                               weight_var = "V1028",
                               anchor = "quarter",
                               calibrate = FALSE)
# Result has ref_month_in_quarter, ref_fortnight_in_quarter, ref_week_in_quarter
# but no weight_monthly column
```

---

## Using for Monthly Analysis

```{r monthly-analysis}
# Compute monthly unemployment rate
monthly_unemployment <- result[determined_month == TRUE, .(
  unemployment_rate = sum((VD4002 == 2) * weight_monthly, na.rm = TRUE) /
                      sum((VD4001 == 1) * weight_monthly, na.rm = TRUE)
), by = ref_month_yyyymm]

# Compute monthly population
monthly_pop <- result[, .(
  population = sum(weight_monthly, na.rm = TRUE)
), by = ref_month_yyyymm]
```

**Note:** Use `determined_month == TRUE` to filter to observations with determined months.

---

## Understanding Determination Rates

### Why Stack Multiple Quarters?

PNADC uses a **rotating panel** where each household (identified by UPA + V1014) is interviewed in 5 consecutive quarters. Crucially, the same household is always interviewed in the **same relative month position** within each quarter.

This means birthday constraints from **any** quarter can determine the month for **all** quarters:

```
UPA=123456, V1014=1 appears in 5 quarters:

  2023-Q1: could be Jan or Feb (ambiguous)
  2023-Q2: could be Apr, May, or Jun (ambiguous)
  2023-Q3: must be August (birthday constraint pins it down!)
  2023-Q4: could be Oct or Nov (ambiguous)
  2024-Q1: could be Feb or Mar (ambiguous)

Cross-quarter aggregation:
  Since 2023-Q3 must be month 2, ALL quarters must be month 2.
  Result: ALL 5 quarters are determined!
```

**Benchmark results (2012-2025, 55 quarters, 28.4M observations):**

| Processing Mode | Month Rate | Fortnight Rate | Week Rate |
|-----------------|------------|----------------|-----------|
| Single quarter (1Q) | ~70% | ~7% | ~2% |
| 8 quarters (2 years) | ~94% | ~9% | ~3% |
| 55 quarters (full history) | **97.0%** | **9.2%** | **3.3%** |

**Important:** Strict fortnight and week determination rates remain at ~9% and ~3% regardless of stacking because their constraints cannot aggregate across quarters - each quarter's interview timing is independent at the sub-monthly level. Only month determination benefits from cross-quarter aggregation through the rotating panel design.

### What Makes Observations Indeterminate?

About 3% of observations remain indeterminate for months because:

- **Incomplete panel coverage**: First/last 4 quarters in your data have fewer panel visits
- **Missing birth dates**: Some respondents don't report birth date (V2008=99, etc.)
- **Small households**: Fewer people means fewer birthday constraints
- **Unit non-response**: Some households don't respond in all quarters

For the full algorithm explanation, see [How PNADCperiods Works](how-it-works.html).

---

## Experimental Strategies for Improved Rates

For analyses requiring higher determination rates, experimental strategies can improve rates by making informed probabilistic assignments:

```{r experimental}
# Build standard crosswalk first (with date bounds for experimental strategies)
crosswalk <- pnadc_identify_periods(pnadc_stacked, store_date_bounds = TRUE)

# Apply experimental strategies
crosswalk_exp <- pnadc_experimental_periods(
  crosswalk,
  strategy = "both",              # "probabilistic", "upa_aggregation", or "both"
  confidence_threshold = 0.9,     # Only assign when >= 90% confident
  upa_proportion_threshold = 0.5  # UPA consensus threshold
)

# Check improvement
crosswalk_exp[, .(
  month_rate = mean(determined_month),
  fortnight_rate = mean(determined_fortnight),
  week_rate = mean(determined_week)
)]
```

**Benchmark results (2019-2020, 8 quarters):**

| Configuration | Month % | Fortnight % | Week % | Notes |
|---------------|---------|-------------|--------|-------|
| Strict only | 94.3% | 8.9% | 3.3% | Deterministic only |
| + Probabilistic (conf=0.8) | **97.3%** | **13.5%** | **7.5%** | Best for week determination |
| + Probabilistic (conf=0.9) | **97.3%** | **13.5%** | 3.6% | Conservative |
| + Both (conf=0.9) | **97.3%** | **13.5%** | 3.6% | Recommended |

**Note:** The UPA aggregation strategy provides minimal additional improvement (~0.1pp) because the probabilistic strategy already captures most cases. Using `strategy = "both"` is recommended for future-proofing.

**Recommended settings:**

- **Conservative:** `confidence_threshold = 0.9` - maximizes month/fortnight while being cautious on weeks
- **Maximum coverage:** `confidence_threshold = 0.8` - best week determination (7.5%)

See the [How PNADCperiods Works](how-it-works.html) vignette for detailed documentation on experimental strategies.

---

## Annual Data Workflow

Annual PNADC data achieves even higher determination rates because the crosswalk covers more complete panel cycles:

```{r annual-workflow}
# Apply crosswalk to annual data
result_annual <- pnadc_apply_periods(
  pnadc_annual,
  crosswalk,
  weight_var = "V1032",  # Annual weight variable
  anchor = "year",       # Annual anchor
  calibrate = TRUE,
  calibration_unit = "month"
)
```

**Annual data benchmark (2019-2020):**

| Metric | Value |
|--------|-------|
| Month match rate | **98.0%** |
| Weight CV | 1.05 |
| Negative weights | 0 |

---

## Calibration Quality

All calibration configurations produce high-quality weights with no negative values:

| Anchor | Unit | Smooth | Match Rate | Weight CV | Negative Weights |
|--------|------|--------|------------|-----------|------------------|
| Quarter | Month | Yes | 94.3% | 1.19 | 0 |
| Quarter | Month | No | 94.3% | 1.20 | 0 |
| Quarter | Fortnight | Yes | 8.9% | 1.21 | 0 |
| Quarter | Week | - | 3.3% | 2.83 | 0 |
| Year | Month | Yes | 98.0% | 1.05 | 0 |
| Year | Month | No | 98.0% | 1.06 | 0 |

**Notes:**

- Weight CV (coefficient of variation) increases for finer time periods due to smaller sample sizes
- The `smooth` parameter applies rolling-window smoothing to population targets, reducing weight variability
- Annual data produces more stable weights due to larger sample sizes per period

---

## Next Steps

- **Download PNADC data**: See [Download and Prepare Data](download-and-prepare.html) for a complete workflow to download and stack quarterly microdata from IBGE.

- **Analysis examples**: See [Applied Examples](applied-examples.html) for real-world labor market analysis comparing monthly vs quarterly data, including COVID unemployment and minimum wage validation.

- **Annual PNADC data**: Working with annual income data? See [Monthly Poverty Analysis with Annual PNADC Data](annual-poverty-analysis.html) for the workflow using annual data.

- **Algorithm details**: See [How PNADCperiods Works](how-it-works.html) for the complete methodology, including experimental strategies and weight calibration.

- **Function reference**: Browse the [Reference](../reference/index.html) for documentation of all exported functions.

---

## Quick Reference

### Main Functions

```r
# Step 1: Build crosswalk from stacked data
pnadc_identify_periods(
  data,                    # Stacked PNADC data
  verbose = TRUE,          # Show progress?
  store_date_bounds = TRUE # Store bounds for experimental strategies?
)

# Step 2: Apply crosswalk and optionally calibrate weights
pnadc_apply_periods(
  data,              # PNADC data to augment
  crosswalk,         # Crosswalk from pnadc_identify_periods()
  weight_var,        # REQUIRED: "V1028" (quarterly) or "V1032" (annual)
  anchor,            # REQUIRED: "quarter" or "year"
  calibrate = TRUE,  # Calibrate weights to SIDRA population?
  calibration_unit = "month",  # "month", "fortnight", or "week"
  target_totals = NULL,        # Custom targets (NULL = auto-fetch)
  smooth = TRUE,     # Apply smoothing to weights?
  keep_all = TRUE,   # Return all rows (including undetermined)?
  verbose = TRUE     # Show progress?
)

# Optional: Experimental strategies for improved rates
pnadc_experimental_periods(
  crosswalk,                     # Crosswalk from pnadc_identify_periods()
  strategy = "both",             # "probabilistic", "upa_aggregation", or "both"
  confidence_threshold = 0.9,    # Threshold for probabilistic assignment
  upa_proportion_threshold = 0.5 # Threshold for UPA aggregation
)
```

### Performance (2012-2025 benchmark, 28.4M observations)

| Metric | Value |
|--------|-------|
| Month determination | **97.0%** |
| Fortnight determination | **9.2%** |
| Week determination | **3.3%** |
| Negative weights | 0 |
| Errors | 0 |

See the [How PNADCperiods Works](how-it-works.html) vignette for comprehensive benchmarks.
